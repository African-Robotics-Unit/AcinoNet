{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.stats import linregress\n",
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory, SolverStatus, TerminationCondition\n",
    "from lib import misc, utils, app\n",
    "from lib.calib import triangulate_points_fisheye\n",
    "\n",
    "mplstyle_fpath = plt.style.use(os.path.join('..', 'configs', 'mplstyle.yaml'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOT_DATA_DIR = os.path.join(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Params\n",
    "Define the params in the cell below. Thereafter, run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(ROOT_DATA_DIR, \"2019_03_09\", \"lily\", \"run\")\n",
    "DATA_DIR = os.path.join(ROOT_DATA_DIR, \"2017_08_29\", \"top\", \"jules\", \"run1_1\")\n",
    "\n",
    "start_frame = 50\n",
    "end_frame = 115\n",
    "\n",
    "# DLC p_cutoff - any points with likelihood < dlc_thresh are not trusted in FTE\n",
    "dlc_thresh = 0.8  # change this only if FTE result is unsatisfactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF REDESCENDING, ABSOLUTE AND QUADRATIC COST FUNCTIONS\n",
    "# we use a redescending cost to stop outliers affecting the optimisation negatively\n",
    "redesc_a = 3\n",
    "redesc_b = 10\n",
    "redesc_c = 20\n",
    "\n",
    "# plot\n",
    "r_x = np.arange(-20,20, 1e-1)\n",
    "r_y1 = [misc.redescending_loss(i, redesc_a, redesc_b, redesc_c) for i in r_x]\n",
    "r_y2 = abs(r_x)\n",
    "r_y3 = r_x**2\n",
    "plt.figure()\n",
    "plt.plot(r_x,r_y1, label=\"Redescending\")\n",
    "plt.plot(r_x,r_y2, label=\"Absolute (linear)\")\n",
    "plt.plot(r_x,r_y3, label=\"Quadratic\")\n",
    "ax = plt.gca()\n",
    "ax.set_ylim((-5, 50))\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "## Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(DATA_DIR)\n",
    "OUT_DIR = os.path.join(DATA_DIR, 'fte')\n",
    "DLC_DIR = os.path.join(DATA_DIR, 'dlc')\n",
    "assert os.path.exists(DLC_DIR)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "start_frame -= 1; # 0 based indexing\n",
    "N = end_frame-start_frame\n",
    "Ts = 1/120 if '2019' in DATA_DIR else 1/90 # timestep\n",
    "print(f\"Framerate: {1/Ts} fps\")\n",
    "\n",
    "# ========= POSE FUNCTIONS ========\n",
    "\n",
    "def pt3d_to_2d(x, y, z, K, D, R, t):\n",
    "    x_2d = x*R[0,0] + y*R[0,1] + z*R[0,2] + t.flatten()[0]\n",
    "    y_2d = x*R[1,0] + y*R[1,1] + z*R[1,2] + t.flatten()[1]\n",
    "    z_2d = x*R[2,0] + y*R[2,1] + z*R[2,2] + t.flatten()[2]\n",
    "    #project onto camera plane\n",
    "    a = x_2d/z_2d\n",
    "    b = y_2d/z_2d\n",
    "    #fisheye params\n",
    "    r = (a**2 + b**2 +1e-12)**0.5 \n",
    "    th = atan(r)\n",
    "    #distortion\n",
    "    th_D = th * (1 + D[0]*th**2 + D[1]*th**4 + D[2]*th**6 + D[3]*th**8)\n",
    "    x_P = a*th_D/r\n",
    "    y_P = b*th_D/r\n",
    "    u = K[0,0]*x_P + K[0,2]\n",
    "    v = K[1,1]*y_P + K[1,2]\n",
    "    return u, v\n",
    "\n",
    "\n",
    "# SYMBOLIC CHEETAH POSE POSITIONS\n",
    "idx = misc.get_pose_params()\n",
    "x = sp.symbols(list(idx.keys()))\n",
    "positions = misc.get_3d_marker_coords(x)\n",
    "\n",
    "# ========= LAMBDIFY SYMBOLIC FUNCTIONS ========\n",
    "func_map = {\"sin\":sin, \"cos\":cos, \"ImmutableDenseMatrix\":np.array} \n",
    "pose_to_3d = sp.lambdify(x, positions, modules=[func_map])\n",
    "pos_funcs = []\n",
    "for i in range(positions.shape[0]):\n",
    "    lamb = sp.lambdify(x, positions[i,:], modules=[func_map])\n",
    "    pos_funcs.append(lamb)\n",
    "\n",
    "# ========= IMPORT CAMERA & SCENE PARAMS ========\n",
    "K_arr, D_arr, R_arr, t_arr, cam_res, n_cams, scene_fpath = utils.find_scene_file(DATA_DIR)\n",
    "D_arr = D_arr.reshape((-1,4))\n",
    "\n",
    "# ========= IMPORT DATA ========\n",
    " \n",
    "R = 5 # measurement standard deviation\n",
    "\n",
    "Q_list = [ # model parameters variance\n",
    "    4, 7, 5,    # head position in inertial\n",
    "    13, 9, 26,  # head rotation in inertial\n",
    "    32, 18, 12, # neck\n",
    "    43,         # front torso\n",
    "    10, 53, 34, # back torso\n",
    "    90, 43,     # tail_base\n",
    "    118, 51,    # tail_mid\n",
    "    247, 186,   # l_shoulder, l_front_knee\n",
    "    194, 164,   # r_shoulder, r_front_knee\n",
    "    295, 243,   # l_hip, l_back_knee\n",
    "    334, 149    # r_hip, r_back_knee\n",
    "]\n",
    "Q_list += Q_list[0:3] # lure's x, y, z variance - same as head\n",
    "Q = np.array(Q_list, dtype=np.float64)**2\n",
    "\n",
    "markers = misc.get_markers()\n",
    "\n",
    "def get_meas_from_df(n, c, l, d):\n",
    "    n_mask = points_2d_df[\"frame\"] == n-1\n",
    "    l_mask = points_2d_df[\"marker\"] == markers[l-1]\n",
    "    c_mask = points_2d_df[\"camera\"] == c-1\n",
    "    d_idx = {1:\"x\", 2:\"y\"}\n",
    "    val = points_2d_df[n_mask & l_mask & c_mask]\n",
    "    return val[d_idx[d]].values[0]\n",
    "\n",
    "def get_likelihood_from_df(n, c, l):\n",
    "    n_mask = points_2d_df[\"frame\"] == n-1\n",
    "    l_mask = points_2d_df[\"marker\"] == markers[l-1]\n",
    "    c_mask = points_2d_df[\"camera\"] == c-1\n",
    "    val = points_2d_df[n_mask & l_mask & c_mask]\n",
    "    return val[\"likelihood\"].values[0]\n",
    "\n",
    "# ========= PROJECTION FUNCTIONS ========\n",
    "def pt3d_to_x2d(x, y, z, K, D, R, t):\n",
    "    u = pt3d_to_2d(x, y, z, K, D, R, t)[0]\n",
    "    return u\n",
    "\n",
    "def pt3d_to_y2d(x, y, z, K, D, R, t):\n",
    "    v = pt3d_to_2d(x, y, z, K, D, R, t)[1]\n",
    "    return v\n",
    "\n",
    "proj_funcs = [pt3d_to_x2d, pt3d_to_y2d]\n",
    "\n",
    "#===================================================\n",
    "#                   Load in data\n",
    "#===================================================\n",
    "print(\"Loading data\")\n",
    "\n",
    "df_paths = glob(os.path.join(DLC_DIR, '*.h5'))\n",
    "\n",
    "points_2d_df = utils.load_dlc_points_as_df(df_paths)\n",
    "points_3d_df = utils.get_pairwise_3d_points_from_df(\n",
    "    points_2d_df[points_2d_df['likelihood']>dlc_thresh],\n",
    "    K_arr, D_arr, R_arr, t_arr,\n",
    "    triangulate_points_fisheye\n",
    ")\n",
    "\n",
    "#===================================================\n",
    "#                   Optimisation\n",
    "#===================================================\n",
    "print(\"\\nStarted Optimisation\")\n",
    "m = ConcreteModel(name = \"Cheetah from measurements\")\n",
    "m.Ts = Ts\n",
    "\n",
    "# ===== SETS =====\n",
    "N = end_frame-start_frame # number of timesteps in trajectory\n",
    "P = len(x)                # number of pose parameters\n",
    "L = len(pos_funcs)        # number of dlc labels per frame\n",
    "C = n_cams                # number of cameras\n",
    "D2 = 2                    # dimensionality of measurements (image points)\n",
    "D3 = 3                    # dimensionality of measurements (3d points)\n",
    "\n",
    "m.N = RangeSet(N)\n",
    "m.P = RangeSet(P)\n",
    "m.L = RangeSet(L)\n",
    "m.C = RangeSet(C)\n",
    "m.D2 = RangeSet(D2)\n",
    "m.D3 = RangeSet(D3)\n",
    "\n",
    "# ======= WEIGHTS =======\n",
    "def init_meas_weights(model, n, c, l):\n",
    "    likelihood = get_likelihood_from_df(n+start_frame, c, l)\n",
    "    if likelihood > dlc_thresh:\n",
    "        return 1/R\n",
    "    else:\n",
    "        return 0\n",
    "m.meas_err_weight = Param(m.N, m.C, m.L, initialize=init_meas_weights, mutable=True)  # IndexError: index 0 is out of bounds for axis 0 with size 0 means that N is too large\n",
    "\n",
    "def init_model_weights(m, p):\n",
    "    if Q[p-1] != 0.0:\n",
    "        return 1/Q[p-1]\n",
    "    else:\n",
    "        return 0\n",
    "m.model_err_weight = Param(m.P, initialize=init_model_weights)\n",
    "\n",
    "# ===== PARAMETERS =====\n",
    "print(\"Initialising params & variables\")\n",
    "\n",
    "def init_measurements_df(m, n, c, l, d2):\n",
    "    return get_meas_from_df(n+start_frame, c, l, d2)\n",
    "m.meas = Param(m.N, m.C, m.L, m.D2, initialize=init_measurements_df)\n",
    "\n",
    "# ===== VARIABLES =====\n",
    "m.x = Var(m.N, m.P)   # position\n",
    "m.dx = Var(m.N, m.P)  # velocity\n",
    "m.ddx = Var(m.N, m.P) # acceleration\n",
    "m.poses = Var(m.N, m.L, m.D3)\n",
    "m.slack_model = Var(m.N, m.P)\n",
    "m.slack_meas = Var(m.N, m.C, m.L, m.D2, initialize=0.0)\n",
    "\n",
    "# ===== VARIABLES INITIALIZATION =====\n",
    "\n",
    "# estimate initial points\n",
    "frame_est = np.arange(end_frame)\n",
    "init_x = np.zeros((N, P))\n",
    "init_dx = np.zeros((N, P))\n",
    "init_ddx = np.zeros((N, P))\n",
    "\n",
    "lure_pts = points_3d_df[points_3d_df[\"marker\"]==\"lure\"][[\"frame\", \"x\", \"y\", \"z\"]].values\n",
    "lure_x_slope, lure_x_intercept, *_ = linregress(lure_pts[:,0], lure_pts[:,1])\n",
    "lure_y_slope, lure_y_intercept, *_ = linregress(lure_pts[:,0], lure_pts[:,2])\n",
    "lure_z_slope, lure_z_intercept, *_ = linregress(lure_pts[:,0], lure_pts[:,3])\n",
    "lure_x_est = frame_est*lure_x_slope + lure_x_intercept\n",
    "lure_y_est = frame_est*lure_y_slope + lure_y_intercept\n",
    "lure_z_est = frame_est*lure_z_slope + lure_z_intercept\n",
    "\n",
    "init_x[:,idx['x_l']] = lure_x_est[start_frame: end_frame] # x\n",
    "init_x[:,idx['y_l']] = lure_y_est[start_frame: end_frame] # y\n",
    "init_x[:,idx['z_l']] = lure_z_est[start_frame: end_frame] # z\n",
    "\n",
    "points_3d_df = points_3d_df[points_3d_df['frame'].between(start_frame, end_frame-1)]\n",
    "\n",
    "nose_pts = points_3d_df[points_3d_df[\"marker\"]==\"nose\"][[\"frame\", \"x\", \"y\", \"z\"]].values\n",
    "nose_x_slope, nose_x_intercept, *_ = linregress(nose_pts[:,0], nose_pts[:,1])\n",
    "nose_y_slope, nose_y_intercept, *_ = linregress(nose_pts[:,0], nose_pts[:,2])\n",
    "nose_z_slope, nose_z_intercept, *_ = linregress(nose_pts[:,0], nose_pts[:,3])\n",
    "nose_x_est = frame_est*nose_x_slope + nose_x_intercept\n",
    "nose_y_est = frame_est*nose_y_slope + nose_y_intercept\n",
    "nose_z_est = frame_est*nose_z_slope + nose_z_intercept\n",
    "psi_est = np.arctan2(nose_y_slope, nose_x_slope)\n",
    "\n",
    "init_x[:,idx['x_0']] = nose_x_est[start_frame: end_frame] # x\n",
    "init_x[:,idx['y_0']] = nose_y_est[start_frame: end_frame] # y\n",
    "init_x[:,idx['z_0']] = nose_z_est[start_frame: end_frame] # z\n",
    "init_x[:,idx['psi_0']] = psi_est # yaw = psi\n",
    "\n",
    "for n in m.N:\n",
    "    for p in m.P:\n",
    "        if n<len(init_x): #init using known values\n",
    "            m.x[n,p].value = init_x[n-1,p-1]\n",
    "            m.dx[n,p].value = init_dx[n-1,p-1]\n",
    "            m.ddx[n,p].value = init_ddx[n-1,p-1]\n",
    "        else: #init using last known value\n",
    "            m.x[n,p].value = init_x[-1,p-1]\n",
    "            m.dx[n,p].value = init_dx[-1,p-1]\n",
    "            m.ddx[n,p].value = init_ddx[-1,p-1]\n",
    "    #init pose\n",
    "    var_list = [m.x[n,p].value for p in range(1, P+1)]\n",
    "    for l in m.L:\n",
    "        [pos] = pos_funcs[l-1](*var_list)\n",
    "        for d3 in m.D3:\n",
    "            m.poses[n,l,d3].value = pos[d3-1]\n",
    "\n",
    "# ===== CONSTRAINTS =====\n",
    "# 3D POSE\n",
    "def pose_constraint(m,n,l,d3):\n",
    "    #get 3d points\n",
    "    var_list = [m.x[n,p] for p in range(1, P+1)]\n",
    "    [pos] = pos_funcs[l-1](*var_list)\n",
    "    return pos[d3-1] == m.poses[n,l,d3]\n",
    "m.pose_constraint = Constraint(m.N, m.L, m.D3, rule=pose_constraint)\n",
    "\n",
    "# INTEGRATION\n",
    "print(\"Initialising numerical integration\\n\")\n",
    "def backwards_euler_pos(m,n,p): # position\n",
    "    if n > 1:\n",
    "        return m.x[n,p] == m.x[n-1,p] + m.Ts*m.dx[n,p]\n",
    "\n",
    "    else:\n",
    "        return Constraint.Skip\n",
    "m.integrate_p = Constraint(m.N, m.P, rule = backwards_euler_pos)\n",
    "\n",
    "def backwards_euler_vel(m,n,p): # velocity\n",
    "    if n > 1:\n",
    "        return m.dx[n,p] == m.dx[n-1,p] + m.Ts*m.ddx[n,p]\n",
    "    else:\n",
    "        return Constraint.Skip \n",
    "m.integrate_v = Constraint(m.N, m.P, rule = backwards_euler_vel)\n",
    "\n",
    "# MODEL\n",
    "def constant_acc(m, n, p):\n",
    "    if n > 1:\n",
    "        return m.ddx[n,p] == m.ddx[n-1,p] + m.slack_model[n,p]\n",
    "    else:\n",
    "        return Constraint.Skip \n",
    "m.constant_acc = Constraint(m.N, m.P, rule = constant_acc)\n",
    "\n",
    "# MEASUREMENT \n",
    "def measurement_constraints(m, n, c, l, d2):\n",
    "    #project\n",
    "    K, D, R, t = K_arr[c-1], D_arr[c-1], R_arr[c-1], t_arr[c-1]\n",
    "    x, y, z = m.poses[n,l,1], m.poses[n,l,2], m.poses[n,l,3]\n",
    "    return proj_funcs[d2-1](x, y, z, K, D, R, t) - m.meas[n, c, l, d2] - m.slack_meas[n, c, l, d2] == 0\n",
    "m.measurement = Constraint(m.N, m.C, m.L, m.D2, rule = measurement_constraints)\n",
    "\n",
    "#===== POSE CONSTRAINTS =====\n",
    "# Note 1 based indexing for pyomo!!!!...@#^!@#&\n",
    "for state in idx:\n",
    "    idx[state] += 1\n",
    "    \n",
    "#Head\n",
    "def head_psi_0(m,n):\n",
    "    return abs(m.x[n,idx['psi_0']]) <= np.pi/6\n",
    "m.head_psi_0 = Constraint(m.N, rule=head_psi_0)\n",
    "def head_theta_0(m,n):\n",
    "    return abs(m.x[n,idx['theta_0']]) <= np.pi/6\n",
    "m.head_theta_0 = Constraint(m.N, rule=head_theta_0)\n",
    "\n",
    "#Neck\n",
    "def neck_phi_1(m,n):\n",
    "    return abs(m.x[n,idx['phi_1']]) <= np.pi/6\n",
    "m.neck_phi_1 = Constraint(m.N, rule=neck_phi_1)\n",
    "def neck_theta_1(m,n):\n",
    "    return abs(m.x[n,idx['theta_1']]) <= np.pi/6\n",
    "m.neck_theta_1 = Constraint(m.N, rule=neck_theta_1)\n",
    "def neck_psi_1(m,n):\n",
    "    return abs(m.x[n,idx['psi_1']]) <= np.pi/6\n",
    "m.neck_psi_1 = Constraint(m.N, rule=neck_psi_1)\n",
    "\n",
    "#Front torso\n",
    "def front_torso_theta_2(m,n):\n",
    "    return abs(m.x[n,idx['theta_2']]) <= np.pi/6\n",
    "m.front_torso_theta_2 = Constraint(m.N, rule=front_torso_theta_2)\n",
    "\n",
    "#Back torso\n",
    "def back_torso_theta_3(m,n):\n",
    "    return abs(m.x[n,idx['theta_3']]) <= np.pi/6\n",
    "m.back_torso_theta_3 = Constraint(m.N, rule=back_torso_theta_3)\n",
    "def back_torso_phi_3(m,n):\n",
    "    return abs(m.x[n,idx['phi_3']]) <= np.pi/6\n",
    "m.back_torso_phi_3 = Constraint(m.N, rule=back_torso_phi_3)\n",
    "def back_torso_psi_3(m,n):\n",
    "    return abs(m.x[n,idx['psi_3']]) <= np.pi/6\n",
    "m.back_torso_psi_3 = Constraint(m.N, rule=back_torso_psi_3)\n",
    "\n",
    "#Tail base\n",
    "def tail_base_theta_4(m,n):\n",
    "    return abs(m.x[n,idx['theta_4']]) <= np.pi/1.5\n",
    "m.tail_base_theta_4 = Constraint(m.N, rule=tail_base_theta_4)\n",
    "def tail_base_psi_4(m,n):\n",
    "    return abs(m.x[n,idx['psi_4']]) <= np.pi/1.5\n",
    "m.tail_base_psi_4 = Constraint(m.N, rule=tail_base_psi_4)\n",
    "\n",
    "#Tail mid\n",
    "def tail_mid_theta_5(m,n):\n",
    "    return abs(m.x[n,idx['theta_5']]) <= np.pi/1.5\n",
    "m.tail_mid_theta_5 = Constraint(m.N, rule=tail_mid_theta_5)\n",
    "def tail_mid_psi_5(m,n):\n",
    "    return abs(m.x[n,idx['psi_5']]) <= np.pi/1.5 \n",
    "m.tail_mid_psi_5 = Constraint(m.N, rule=tail_mid_psi_5)\n",
    "\n",
    "#Front left leg\n",
    "def l_shoulder_theta_6(m,n):\n",
    "    return abs(m.x[n,idx['theta_6']]) <= np.pi/2\n",
    "m.l_shoulder_theta_6 = Constraint(m.N, rule=l_shoulder_theta_6)\n",
    "def l_front_knee_theta_7(m,n):\n",
    "    return abs(m.x[n,idx['theta_7']] + np.pi/2) <= np.pi/2\n",
    "m.l_front_knee_theta_7 = Constraint(m.N, rule=l_front_knee_theta_7)\n",
    "\n",
    "#Front right leg\n",
    "def r_shoulder_theta_8(m,n):\n",
    "    return abs(m.x[n,idx['theta_8']]) <= np.pi/2\n",
    "m.r_shoulder_theta_8 = Constraint(m.N, rule=r_shoulder_theta_8)\n",
    "def r_front_knee_theta_9(m,n):\n",
    "    return abs(m.x[n,idx['theta_9']] + np.pi/2) <= np.pi/2\n",
    "m.r_front_knee_theta_9 = Constraint(m.N, rule=r_front_knee_theta_9)\n",
    "\n",
    "#Back left leg\n",
    "def l_hip_theta_10(m,n):\n",
    "    return abs(m.x[n,idx['theta_10']]) <= np.pi/2\n",
    "m.l_hip_theta_10 = Constraint(m.N, rule=l_hip_theta_10)\n",
    "def l_back_knee_theta_11(m,n):\n",
    "    return abs(m.x[n,idx['theta_11']] - np.pi/2) <= np.pi/2\n",
    "m.l_back_knee_theta_11 = Constraint(m.N, rule=l_back_knee_theta_11)\n",
    "\n",
    "#Back right leg\n",
    "def r_hip_theta_12(m,n):\n",
    "    return abs(m.x[n,idx['theta_12']]) <= np.pi/2\n",
    "m.r_hip_theta_12 = Constraint(m.N, rule=r_hip_theta_12)\n",
    "def r_back_knee_theta_13(m,n):\n",
    "    return abs(m.x[n,idx['theta_13']] - np.pi/2) <= np.pi/2\n",
    "m.r_back_knee_theta_13 = Constraint(m.N, rule=r_back_knee_theta_13)\n",
    "\n",
    "# ======= OBJECTIVE FUNCTION =======\n",
    "def obj(m):\n",
    "    slack_model_err = 0.0\n",
    "    slack_meas_err = 0.0\n",
    "    for n in m.N:\n",
    "        #Model Error\n",
    "        for p in m.P:\n",
    "            slack_model_err += m.model_err_weight[p] * m.slack_model[n, p] ** 2\n",
    "        #Measurement Error\n",
    "        for l in m.L:\n",
    "            for c in m.C:\n",
    "                for d2 in m.D2:\n",
    "                    slack_meas_err += misc.redescending_loss(m.meas_err_weight[n, c, l] * m.slack_meas[n, c, l, d2], redesc_a, redesc_b, redesc_c)\n",
    "    return slack_meas_err + slack_model_err\n",
    "\n",
    "m.obj = Objective(rule = obj)\n",
    "\n",
    "# RUN THE SOLVER\n",
    "opt = SolverFactory(\n",
    "    'ipopt', # use this if MA86 solver is not installed\n",
    "    # executable='./CoinIpopt/build/bin/ipopt'\n",
    ")\n",
    "\n",
    "# solver options\n",
    "opt.options[\"print_level\"] = 5\n",
    "opt.options[\"max_iter\"] = 10000\n",
    "opt.options[\"max_cpu_time\"] = 3600\n",
    "opt.options[\"tol\"] = 1e-1\n",
    "opt.options[\"OF_print_timing_statistics\"] = \"yes\"\n",
    "opt.options[\"OF_print_frequency_iter\"] = 10\n",
    "opt.options[\"OF_hessian_approximation\"] = \"limited-memory\"\n",
    "# opt.options[\"linear_solver\"] = \"ma86\"\n",
    "\n",
    "results = opt.solve(m, tee=True, keepfiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save FTE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, dx, ddx =  [], [], []\n",
    "for n in m.N:\n",
    "    x.append([value(m.x[n, p]) for p in m.P])\n",
    "    dx.append([value(m.dx[n, p]) for p in m.P])\n",
    "    ddx.append([value(m.ddx[n, p]) for p in m.P])\n",
    "    \n",
    "app.save_fte(dict(x=x, dx=dx, ddx=ddx), OUT_DIR, start_frame)\n",
    "\n",
    "fig_fpath= os.path.join(OUT_DIR, 'fte_result.svg')\n",
    "mplstyle_fpath = plt.style.use(os.path.join('..', 'configs', 'mplstyle.yaml'))\n",
    "app.plot_cheetah_states(x, out_fpath=fig_fpath, mplstyle_fpath=mplstyle_fpath)\n",
    "\n",
    "with open(os.path.join(OUT_DIR, 'fte_padded.pickle'), 'rb') as f:\n",
    "    fte_data=pickle.load(f)\n",
    "vid_fpath = os.path.join(OUT_DIR, 'fte.avi')\n",
    "app.reconstruction_reprojection_video(DATA_DIR, vid_fpath, np.array(fte_data['positions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the cheetah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = os.path.join(OUT_DIR, 'fte.pickle')\n",
    "app.plot_cheetah_reconstruction(data_fpath, hide_lure=True, reprojections=False, centered=True, dark_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fpaths = [os.path.join(DATA_DIR, 'sba', 'sba.pickle'),\n",
    "#                os.path.join(DATA_DIR, 'ekf', 'ekf.pickle'),\n",
    "#                os.path.join(DATA_DIR, 'fte', 'fte.pickle')]\n",
    "# app.plot_multiple_cheetah_reconstructions(data_fpaths, hide_lure=True, reprojections=False, centered=True, dark_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
