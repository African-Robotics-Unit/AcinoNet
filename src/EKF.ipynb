{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy import stats\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sys.path.append('./Calib')\n",
    "# from calib.utils import load_scene\n",
    "from calib import utils, calib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define these params manually. Thereafter, run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_DIR = '../data/2019_03_09'\n",
    "DATA_DIR = os.path.join(ROOT_DATA_DIR,f\"jules_dlc/flick2/res152\")\n",
    "scene_fpath = os.path.join(ROOT_DATA_DIR,'extrinsic_calib/scene_sba.json')\n",
    "\n",
    "start_frame = 30\n",
    "end_frame = 130\n",
    "\n",
    "# DLC p_cutoff - any points with likelihood < dlc_thresh are not trusted in EKF\n",
    "dlc_thresh = 0.8  # change this only if EKF result is unsatisfactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EKF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the indices for the states\n",
    "n_states = 75\n",
    "vel_idx = n_states//3\n",
    "acc_idx = n_states*2//3\n",
    "\n",
    "state_id = [\n",
    "    'x_0', 'y_0', 'z_0',         # head position in inertial\n",
    "    'phi_0', 'theta_0', 'psi_0', # head rotation in inertial\n",
    "    'phi_1', 'theta_1', 'psi_1', # neck\n",
    "    'theta_2',                   # front torso\n",
    "    'phi_3', 'theta_3', 'psi_3', # back torso\n",
    "    'theta_4', 'psi_4',          # tail_base\n",
    "    'theta_5', 'psi_5',          # tail_mid\n",
    "    'theta_6', 'theta_7',        # l_shoulder, l_front_knee\n",
    "    'theta_8', 'theta_9',        # r_shoulder, r_front_knee\n",
    "    'theta_10', 'theta_11',      # l_hip, l_back_knee\n",
    "    'theta_12', 'theta_13'       # r_hip, r_back_knee\n",
    "    ]\n",
    "\n",
    "idx = {}\n",
    "for i, deriv_idx in enumerate([0, vel_idx, acc_idx]):\n",
    "    idx.update({'d'*i+state: deriv_idx+j for j, state in enumerate(state_id)})\n",
    "\n",
    "# define DLC labels\n",
    "markers = [\n",
    "    \"l_eye\", \"r_eye\", \"nose\",\n",
    "    \"neck_base\", \"spine\",\n",
    "    \"tail_base\", \"tail1\", \"tail2\",\n",
    "    \"l_shoulder\", \"l_front_knee\", \"l_front_ankle\",\n",
    "    \"r_shoulder\", \"r_front_knee\", \"r_front_ankle\",\n",
    "    \"l_hip\", \"l_back_knee\", \"l_back_ankle\",\n",
    "    \"r_hip\", \"r_back_knee\", \"r_back_ankle\"\n",
    "    ]\n",
    "n_markers = len(markers)\n",
    "\n",
    "# Load extrinsic params\n",
    "K, D, R, T, cam_res = utils.load_scene(scene_fpath)\n",
    "camera_params = []\n",
    "for r,t,d,k in zip(R,T,D,K):\n",
    "    camera_params.append([r, t, d, k])\n",
    "n_cameras = len(camera_params)\n",
    "\n",
    "# other vars\n",
    "start_frame -= 1 # 0 based indexing\n",
    "n_frames = end_frame - start_frame\n",
    "sigma_bound = 3\n",
    "max_pixel_err = cam_res[0] # used in measurement covariance R\n",
    "sT = 1/90 if max_pixel_err == 1920 else 1/120 # timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot_x(x: np.float):\n",
    "    c = np.cos(x)\n",
    "    s = np.sin(x)\n",
    "    return np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, c, s],\n",
    "        [0, -s, c]\n",
    "    ], dtype=np.float)\n",
    "\n",
    "\n",
    "def rot_y(y: np.float):\n",
    "    c = np.cos(y)\n",
    "    s = np.sin(y)\n",
    "    return np.array([\n",
    "        [c, 0, -s],\n",
    "        [0, 1, 0],\n",
    "        [s, 0, c]\n",
    "    ], dtype=np.float)\n",
    "\n",
    "\n",
    "def rot_z(z: np.float):\n",
    "    c = np.cos(z)\n",
    "    s = np.sin(z)\n",
    "    return np.array([\n",
    "        [c, s, 0],\n",
    "        [-s, c, 0],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float)\n",
    "\n",
    "def get_3d_marker_coords(x: np.ndarray):\n",
    "    \"\"\"Returns a numpy array of the 3D marker coordinates (shape Nx3) for a given state vector x.\n",
    "    \"\"\"\n",
    "    # 1. Rotations\n",
    "    RI_0 = rot_z(x[idx['psi_0']]) @ rot_x(x[idx['phi_0']]) @ rot_y(x[idx['theta_0']]) # Head\n",
    "    R0_I = RI_0.T\n",
    "    RI_1 = rot_z(x[idx['psi_1']]) @ rot_x(x[idx['phi_1']]) @ rot_y(x[idx['theta_1']]) @ RI_0 # Neck\n",
    "    R1_I = RI_1.T\n",
    "    RI_2 = rot_y(x[idx['theta_2']]) @ RI_1 # Front torso\n",
    "    R2_I = RI_2.T\n",
    "    RI_3 = rot_z(x[idx['psi_3']]) @ rot_x(x[idx['phi_3']]) @ rot_y(x[idx['theta_3']]) @ RI_2 # Back Torso\n",
    "    R3_I = RI_3.T\n",
    "    RI_4 = rot_z(x[idx['psi_4']]) @ rot_y(x[idx['theta_4']]) @ RI_3 # Tail base\n",
    "    R4_I = RI_4.T\n",
    "    RI_5 = rot_z(x[idx['psi_5']]) @ rot_y(x[idx['theta_5']]) @ RI_4 # Tail mid\n",
    "    R5_I = RI_5.T\n",
    "    RI_6 = rot_y(x[idx['theta_6']]) @ RI_2 # l_shoulder\n",
    "    R6_I = RI_6.T\n",
    "    RI_7 = rot_y(x[idx['theta_7']]) @ RI_6 # l_front_knee\n",
    "    R7_I = RI_7.T\n",
    "    RI_8 = rot_y(x[idx['theta_8']]) @ RI_2 # r_shoulder\n",
    "    R8_I = RI_8.T\n",
    "    RI_9 = rot_y(x[idx['theta_9']]) @ RI_8 # r_front_knee\n",
    "    R9_I = RI_9.T\n",
    "    RI_10 = rot_y(x[idx['theta_10']]) @ RI_3 # l_hip\n",
    "    R10_I = RI_10.T\n",
    "    RI_11 = rot_y(x[idx['theta_11']]) @ RI_10 # l_back_knee\n",
    "    R11_I = RI_11.T\n",
    "    RI_12 = rot_y(x[idx['theta_12']]) @ RI_3 # r_hip\n",
    "    R12_I = RI_12.T\n",
    "    RI_13 = rot_y(x[idx['theta_13']]) @ RI_12 # r_back_knee\n",
    "    R13_I = RI_13.T\n",
    "\n",
    "    # 2. Positions\n",
    "    p_head = np.array([x[[idx['x_0'], idx['y_0'], idx['z_0']]]]).T\n",
    "    p_l_eye = p_head + R0_I @ np.array([[0, 0.03, 0]], dtype=np.float).T\n",
    "    p_r_eye = p_head + R0_I @ np.array([[0, -0.03, 0]], dtype=np.float).T\n",
    "    p_nose = p_head + R0_I @ np.array([[0.055, 0, -0.055]], dtype=np.float).T\n",
    "    \n",
    "    p_neck_base = p_head + R1_I @ np.array([[-0.28, 0, 0]], dtype=np.float).T\n",
    "    p_spine = p_neck_base + R2_I @ np.array([[-0.37, 0, 0]], dtype=np.float).T\n",
    "    \n",
    "    p_tail_base = p_spine + R3_I @ np.array([[-0.37, 0, 0]], dtype=np.float).T\n",
    "    p_tail_mid = p_tail_base + R4_I @ np.array([[-0.28, 0, 0]], dtype=np.float).T\n",
    "    p_tail_tip = p_tail_mid + R5_I @ np.array([[-0.36, 0, 0]], dtype=np.float).T\n",
    "    \n",
    "    p_l_shoulder = p_neck_base + R2_I @ np.array([[-0.04, 0.08, -0.10]], dtype=np.float).T\n",
    "    p_l_front_knee = p_l_shoulder + R6_I @ np.array([[0, 0, -0.24]], dtype=np.float).T\n",
    "    p_l_front_ankle = p_l_front_knee + R7_I @ np.array([[0, 0, -0.28]], dtype=np.float).T\n",
    "    \n",
    "    p_r_shoulder = p_neck_base + R2_I @ np.array([[-0.04, -0.08, -0.10]], dtype=np.float).T\n",
    "    p_r_front_knee = p_r_shoulder + R8_I @ np.array([[0, 0, -0.24]], dtype=np.float).T\n",
    "    p_r_front_ankle = p_r_front_knee + R9_I @ np.array([[0, 0, -0.28]], dtype=np.float).T\n",
    "\n",
    "    p_l_hip = p_tail_base + R3_I @ np.array([[0.12, 0.08, -0.06]], dtype=np.float).T\n",
    "    p_l_back_knee = p_l_hip + R10_I @ np.array([[0, 0, -0.32]], dtype=np.float).T\n",
    "    p_l_back_ankle = p_l_back_knee + R11_I @ np.array([[0, 0, -0.25]], dtype=np.float).T\n",
    "\n",
    "    p_r_hip = p_tail_base + R3_I @ np.array([[0.12, -0.08, -0.06]], dtype=np.float).T\n",
    "    p_r_back_knee = p_r_hip + R12_I @ np.array([[0, 0, -0.32]], dtype=np.float).T\n",
    "    p_r_back_ankle = p_r_back_knee + R13_I @ np.array([[0, 0, -0.25]], dtype=np.float).T\n",
    "\n",
    "    coords_3d = np.array([\n",
    "        p_l_eye, p_r_eye, p_nose,\n",
    "        p_neck_base, p_spine, \n",
    "        p_tail_base, p_tail_mid, p_tail_tip,\n",
    "        p_l_shoulder, p_l_front_knee, p_l_front_ankle,\n",
    "        p_r_shoulder, p_r_front_knee, p_r_front_ankle,\n",
    "        p_l_hip, p_l_back_knee, p_l_back_ankle,\n",
    "        p_r_hip, p_r_back_knee, p_r_back_ankle\n",
    "        ], dtype=np.float32)\n",
    "    \n",
    "    return np.reshape(coords_3d, (len(coords_3d), 3))\n",
    "\n",
    "\n",
    "def h_function(x: np.ndarray, R: np.ndarray, T: np.ndarray, D: np.ndarray, K: np.ndarray):\n",
    "    \"\"\"Returns a numpy array of the 2D marker pixel coordinates (shape Nx2) for a given state vector x and camera parameters R, T, D, K.\n",
    "    \"\"\"\n",
    "    coords_3d = get_3d_marker_coords(x)\n",
    "    coords_2d = calib.project_points_fisheye(coords_3d, K, D, R, T) # Project the 3D positions to 2D\n",
    "    \n",
    "    return coords_2d\n",
    "\n",
    "\n",
    "def predict_next_state(x: np.ndarray, dt: np.float):\n",
    "    \"\"\"Returns a numpy array of the predicted states for a given state vector x and time delta dt.\n",
    "    \"\"\"\n",
    "    acc_prediction = x[acc_idx:]\n",
    "    vel_prediction = x[vel_idx:acc_idx] + dt*acc_prediction\n",
    "    pos_prediction = x[:vel_idx] + dt*vel_prediction + (0.5*dt**2)*acc_prediction\n",
    "    \n",
    "    return np.concatenate([pos_prediction, vel_prediction, acc_prediction]).astype(np.float32)\n",
    "\n",
    "\n",
    "def numerical_jacobian(func, x: np.ndarray, *args):\n",
    "    \"\"\"Returns a numerically approximated jacobian of func with respect to x.\n",
    "    Additional parameters will be passed to func using *args in the format: func(*x, *args)\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    eps = 1e-3\n",
    "    \n",
    "    fx = func(x, *args).flatten()\n",
    "    xpeturb=x.copy()\n",
    "    jac = np.empty((len(fx), n))\n",
    "    for i in range(n):\n",
    "        xpeturb[i] = xpeturb[i]+eps\n",
    "        jac[:,i] = (func(xpeturb, *args).flatten() - fx)/eps\n",
    "        xpeturb[i]=x[i]\n",
    "        \n",
    "    return jac\n",
    "\n",
    "\n",
    "def save_data(fpath, states_est_hist, smooth_states_est_hist):\n",
    "    \n",
    "    positions = np.array([get_3d_marker_coords(states) for states in states_est_hist])\n",
    "    smooth_positions = np.array([get_3d_marker_coords(states) for states in smooth_states_est_hist])\n",
    "    file_data = dict(\n",
    "        positions=positions,\n",
    "        smooth_positions=smooth_positions,\n",
    "        states=states_est_hist,\n",
    "        smooth_states=smooth_states_est_hist,\n",
    "    )\n",
    "\n",
    "    with open(fpath, 'wb') as f:\n",
    "        pickle.dump(file_data, f)\n",
    "        \n",
    "    print(f'saved {fpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DLC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DLC 2D point files (.h5 outputs)\n",
    "dlc_2d_point_files = sorted(glob.glob(os.path.join(DATA_DIR, '*.h5')))\n",
    "assert(len(dlc_2d_point_files) == n_cameras), \"# of dlc '.h5' files != # of cams in extrinsic calib file 'scene*.json'\"\n",
    "\n",
    "# Load Measurement Data (pixels, likelihood)\n",
    "points_2d_df = utils.create_dlc_points_2d_file(dlc_2d_point_files)\n",
    "print(\"DLC points dataframe:\\n\", points_2d_df)\n",
    "\n",
    "# Restructure dataframe\n",
    "points_df = points_2d_df.set_index(['frame', 'camera','marker'])\n",
    "points_df = points_df.stack().unstack(level=1).unstack(level=1).unstack()\n",
    "\n",
    "# Pixels array\n",
    "pixels_df = points_df.loc[:, (range(n_cameras), markers, ['x','y'])]\n",
    "pixels_df = pixels_df.reindex(columns=pd.MultiIndex.from_product([range(n_cameras), markers, ['x','y']]))\n",
    "pixels_arr = pixels_df.to_numpy() #shape - (n_frames, n_cameras * n_markers * 2)\n",
    "\n",
    "# Likelihood array\n",
    "likelihood_df = points_df.loc[:, (range(n_cameras), markers, 'likelihood')]\n",
    "likelihood_df = likelihood_df.reindex(columns=pd.MultiIndex.from_product([range(n_cameras), markers, ['likelihood']]))\n",
    "likelihood_arr = likelihood_df.to_numpy() #shape - (n_frames, n_cameras * n_markers * 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise EKF matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points_2d_filtered_df_temp = points_2d_df[(points_2d_df['likelihood']>dlc_thresh) & (start_frame <= points_2d_df['frame'] < end_frame)]\n",
    "points_3d_df = calib.get_pairwise_3d_points_from_df(\n",
    "    points_2d_df[points_2d_df['likelihood']>dlc_thresh], # ignore points with low likelihood\n",
    "    K, D.reshape((-1,4)), R, T,\n",
    "    calib.triangulate_points_fisheye\n",
    ")\n",
    "\n",
    "# estimate initial points\n",
    "nose_pts = points_3d_df[points_3d_df[\"marker\"]==\"nose\"][[\"frame\", \"x\", \"y\", \"z\"]].values\n",
    "x_slope, x_intercept, *_ = stats.linregress(nose_pts[:,0], nose_pts[:,1]) \n",
    "y_slope, y_intercept, *_ = stats.linregress(nose_pts[:,0], nose_pts[:,2])\n",
    "\n",
    "x_est = start_frame*x_slope + x_intercept # initial nose x\n",
    "y_est = start_frame*y_slope + y_intercept # initial nose y\n",
    "psi_est = np.arctan2(y_slope, x_slope)    # initial yaw angle relative to inertial\n",
    "\n",
    "# INITIAL STATES\n",
    "states = np.zeros(n_states)\n",
    "states[[idx['x_0'], idx['y_0'],idx['psi_0']]] = [x_est, y_est, psi_est] # head x, y & psi (yaw) in inertial\n",
    "states[[idx['dx_0'], idx['dy_0']]] = [x_slope/sT, y_slope/sT]          # head x & y velocity in inertial\n",
    "\n",
    "# State prediction function jacobian F - shape: (n_states, n_states)\n",
    "rng = np.arange(n_states - vel_idx)\n",
    "rng_acc = np.arange(n_states - acc_idx)\n",
    "F = np.eye(n_states, dtype=np.float32)\n",
    "F[rng, rng+vel_idx] = sT\n",
    "F[rng_acc, rng_acc+acc_idx] = sT**2/2\n",
    "\n",
    "# INITIAL STATE COVARIANCE P - how much do we trust the initial states\n",
    "# acceleration\n",
    "p_lin_acc = np.ones(3)*3**2\n",
    "p_ang_acc = np.ones(22)*3**2\n",
    "p_ang_acc[10:] = 5**2\n",
    "# velocity\n",
    "p_lin_vel = np.ones(3)*5**2          # Know this within 2.5m/s and it's a uniform random variable \n",
    "p_ang_vel = np.ones(22)*3**2\n",
    "# position\n",
    "p_lin_pos = np.ones(3)*3**2          # Know initial position within 4m\n",
    "p_ang_pos = np.ones(22)*(np.pi/4)**2 # Know initial angles within 60 degrees, heading may need to change\n",
    "\n",
    "P = np.diag(np.concatenate([p_lin_pos, p_ang_pos, p_lin_vel, p_ang_vel, p_lin_acc, p_ang_acc]))\n",
    "\n",
    "# PROCESS COVARIANCE Q - how \"noisy\" the constant acceleration model is\n",
    "qb = (np.diag([\n",
    "    5.0, 5.0, 5.0,    # head x, y, z in inertial\n",
    "    10.0, 10.0, 10.0, # head phi, theta, psi in inertial\n",
    "    5.0, 25.0, 5.0,   # neck phi, theta, psi\n",
    "    50.0,             # front-torso theta\n",
    "    5.0, 50.0, 25.0,  # back torso phi, theta, psi\n",
    "    100.0, 30.0,      # tail base theta, psi\n",
    "    140.0, 40.0,      # tail mid theta, psi\n",
    "    350.0, 200.0,     # l_shoulder theta, l_front_knee theta\n",
    "    350.0, 200.0,     # r_shoulder theta, r_front_knee theta\n",
    "    450.0, 400.0,     # l_hip theta, l_back_knee theta\n",
    "    450.0, 400.0      # r_hip theta, r_back_knee theta\n",
    "])/2)**2\n",
    "\n",
    "Q = np.block([\n",
    "    [sT**4/4 * qb, sT**3/2 * qb, sT**2/2 * qb],\n",
    "    [sT**3/2 * qb, sT**2 * qb, sT * qb],\n",
    "    [sT**2/2 * qb, sT * qb, qb],\n",
    "    \n",
    "])\n",
    "\n",
    "# MEASUREMENT COVARIANCE R\n",
    "dlc_cov = 5**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run EKF & Smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate space for storing EKF data\n",
    "states_est_hist = np.zeros((n_frames, n_states))\n",
    "states_pred_hist = states_est_hist.copy()\n",
    "P_est_hist = np.zeros((n_frames, n_states, n_states))\n",
    "P_pred_hist = P_est_hist.copy()\n",
    "\n",
    "outliers_ignored = 0\n",
    "\n",
    "for i in range(n_frames):\n",
    "    print(f\"Running frame {i+start_frame+1}\\r\", end='')\n",
    "    \n",
    "    # ========== PREDICTION ==========\n",
    "\n",
    "    # Predict State\n",
    "    states = predict_next_state(states, sT).flatten()\n",
    "    states_pred_hist[i] = states\n",
    "\n",
    "    # Projection of the state covariance\n",
    "    P = F @ P @ F.T + Q\n",
    "    P_pred_hist[i] = P\n",
    "    \n",
    "    # ============ UPDATE ============\n",
    "    \n",
    "    z_k = pixels_arr[i+start_frame]\n",
    "    likelihood = likelihood_arr[i+start_frame]\n",
    "    \n",
    "    # Measurement\n",
    "    H = np.zeros((n_cameras*n_markers*2, n_states))\n",
    "    h = np.zeros((n_cameras*n_markers*2)) # same as H[:, 0].copy()\n",
    "    for j in range(n_cameras):\n",
    "        # State measurement\n",
    "        h[j*n_markers*2:(j+1)*n_markers*2] = h_function(states[:vel_idx], *camera_params[j]).flatten()\n",
    "        # Jacobian - shape: (2*n_markers, n_states)\n",
    "        H[j*n_markers*2:(j+1)*n_markers*2, 0:vel_idx] = numerical_jacobian(h_function, states[:vel_idx], *camera_params[j])\n",
    "    \n",
    "    # Measurement Covariance R\n",
    "    bad_point_mask = np.repeat(likelihood<dlc_thresh, 2)\n",
    "    dlc_cov_arr = dlc_cov*np.ones((n_cameras*n_markers*2))\n",
    "    dlc_cov_arr[bad_point_mask] = max_pixel_err # change this to be independent of cam res?\n",
    "    R = np.diag(dlc_cov_arr**2)\n",
    "\n",
    "    # Residual\n",
    "    residual = z_k - h\n",
    "\n",
    "    # Residual Covariance S\n",
    "    S = (H @ P @ H.T) + R\n",
    "    temp = sigma_bound*np.sqrt(np.diag(S)) # if measurement residual is worse than 3 sigma, set residual to 0 and rely on predicted state only\n",
    "    for j in range(0, len(residual), 2):\n",
    "        if np.abs(residual[j])>temp[j] or np.abs(residual[j+1])>temp[j+1]:\n",
    "            residual[j:j+2] = 0\n",
    "            outliers_ignored += 1\n",
    "        \n",
    "    # Kalman Gain\n",
    "    K = P @ H.T @ np.linalg.inv(S)\n",
    "\n",
    "    # Correction\n",
    "    states = states + K @ residual\n",
    "    states_est_hist[i] = states\n",
    "\n",
    "    # Update State Covariance\n",
    "    P = (np.eye(K.shape[0]) - K @ H) @ P\n",
    "    P_est_hist[i] = P\n",
    "    \n",
    "print(\"Outliers ignored:\", outliers_ignored)\n",
    "\n",
    "# Run Kalman Smoother\n",
    "smooth_states_est_hist = states_est_hist.copy()\n",
    "smooth_P_est_hist = P_est_hist.copy()\n",
    "for i in range(n_frames-2, 0, -1):\n",
    "    A = P_est_hist[i] @ F.T @ np.linalg.inv(P_pred_hist[i+1])\n",
    "    smooth_states_est_hist[i] = states_est_hist[i] + A @ (smooth_states_est_hist[i+1] - states_pred_hist[i+1])\n",
    "    smooth_P_est_hist[i] = P_est_hist[i] + A @ (smooth_P_est_hist[i+1] - P_pred_hist[i+1]) @ A.T\n",
    "    \n",
    "print(\"\\nKalman Smoother complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save EKF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(os.path.join(DATA_DIR,'ekf.pickle'), states_est_hist, smooth_states_est_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(8, 2, figsize=(13,30))\n",
    "# Head\n",
    "axs[0,0].plot(states_est_hist[:, [idx['x_0'], idx['y_0'], idx['z_0']]])\n",
    "axs[0,0].plot(smooth_states_est_hist[:, [idx['x_0'], idx['y_0'], idx['z_0']]], linestyle='dashed')\n",
    "axs[0,0].set_title(\"Head positions\")\n",
    "axs[0,0].legend(['x 0', 'y 0', 'z 0', 'x 0 (smoothed)', 'y 0 (smoothed)', 'z 0 (smoothed)'])\n",
    "\n",
    "# Head\n",
    "# axs[0,1].plot(states_est_hist[:, [d_x_0, d_y_0, d_z_0]])\n",
    "# axs[0,1].plot(smooth_states_est_hist[:, [d_x_0, d_y_0, d_z_0]], linestyle='dashed')\n",
    "# axs[0,1].set_title(\"Head velocity\")\n",
    "# axs[0,1].legend(['dx 0', 'dy 0', 'dz 0', 'dx 0 (smoothed)', 'dy 0 (smoothed)', 'dz 0 (smoothed)'])\n",
    "\n",
    "axs[1,0].plot(states_est_hist[:, [idx['phi_0'], idx['theta_0'], idx['psi_0']]])\n",
    "axs[1,0].plot(smooth_states_est_hist[:, [idx['phi_0'], idx['theta_0'], idx['psi_0']]], linestyle='dashed')\n",
    "axs[1,0].set_title(\"Head angles\")\n",
    "axs[1,0].legend(['phi 0', 'theta 0', 'psi 0', 'phi 0 (smoothed)', 'theta 0 (smoothed)', 'psi 0 (smoothed)'])\n",
    "\n",
    "axs[1,1].plot(states_est_hist[:, [phi_1, theta_1, psi_1]])\n",
    "axs[1,1].plot(smooth_states_est_hist[:, [phi_1, theta_1, psi_1]], linestyle='dashed')\n",
    "axs[1,1].set_title(\"Neck angles\")\n",
    "axs[1,1].legend(['phi 1', 'theta 1', 'psi 1', 'phi 1 (smoothed)', 'theta 1 (smoothed)', 'psi 1 (smoothed)'])\n",
    "\n",
    "axs[2,0].plot(states_est_hist[:, [theta_2]])\n",
    "axs[2,0].plot(smooth_states_est_hist[:, [theta_2]], linestyle='dashed')\n",
    "axs[2,0].set_title(\"Front torso angles\")\n",
    "axs[2,0].legend(['theta_2', 'theta_2 (smoothed)'])\n",
    "\n",
    "axs[2,1].plot(states_est_hist[:, [phi_3, theta_3, psi_3]])\n",
    "axs[2,1].plot(smooth_states_est_hist[:, [phi_3, theta_3, psi_3]], linestyle='dashed')\n",
    "axs[2,1].set_title(\"Back torso angles\")\n",
    "axs[2,1].legend(['phi_3', 'theta_3', 'psi_3', 'phi_3 (smoothed)', 'theta_3 (smoothed)', 'psi_3 (smoothed)'])\n",
    "\n",
    "axs[3,0].plot(states_est_hist[:, [theta_4, psi_4]])\n",
    "axs[3,0].plot(smooth_states_est_hist[:, [theta_4, psi_4]], linestyle='dashed')\n",
    "axs[3,0].set_title(\"Tail base\")\n",
    "axs[3,0].legend(['theta_4', 'psi_4','theta_4 (smoothed)', 'psi_4 (smoothed)'])\n",
    "\n",
    "axs[3,1].plot(states_est_hist[:, [theta_5, psi_5]])\n",
    "axs[3,1].plot(smooth_states_est_hist[:, [theta_5, psi_5]], linestyle='dashed')\n",
    "axs[3,1].set_title(\"Tail Mid\")\n",
    "axs[3,1].legend(['theta_5', 'psi_5', 'theta_5 (smoothed)', 'psi_5 (smoothed)'])\n",
    "\n",
    "axs[4,0].plot(states_est_hist[:, [theta_6]])\n",
    "axs[4,0].plot(smooth_states_est_hist[:, [theta_6]], linestyle='dashed')\n",
    "axs[4,0].set_title(\"Left shoulder angles\")\n",
    "axs[4,0].legend(['theta_6', 'theta_6 (smoothed)'])\n",
    "\n",
    "axs[4,1].plot(states_est_hist[:, [theta_7]])\n",
    "axs[4,1].plot(smooth_states_est_hist[:, [theta_7]], linestyle='dashed')\n",
    "axs[4,1].set_title(\"Left front knee angle\")\n",
    "axs[4,1].legend(['theta_7', 'theta_7 (smoothed)'])\n",
    "\n",
    "axs[5,0].plot(states_est_hist[:, [theta_8]])\n",
    "axs[5,0].plot(smooth_states_est_hist[:, [theta_8]], linestyle='dashed')\n",
    "axs[5,0].set_title(\"Right shoulder angles\")\n",
    "axs[5,0].legend(['theta_8', 'theta_8 (smoothed)'])\n",
    "\n",
    "axs[5,1].plot(states_est_hist[:, [theta_9]])\n",
    "axs[5,1].plot(smooth_states_est_hist[:, [theta_9]], linestyle='dashed')\n",
    "axs[5,1].set_title(\"Right front knee angle\")\n",
    "axs[5,1].legend(['theta_9', 'theta_9 (smoothed)'])\n",
    "\n",
    "axs[6,0].plot(states_est_hist[:, [theta_10]])\n",
    "axs[6,0].plot(smooth_states_est_hist[:, [theta_10]], linestyle='dashed')\n",
    "axs[6,0].set_title(\"Left hip angle\")\n",
    "axs[6,0].legend(['theta_10', 'theta_10 (smoothed)'])\n",
    "\n",
    "axs[6,1].plot(states_est_hist[:, [theta_11]])\n",
    "axs[6,1].plot(smooth_states_est_hist[:, [theta_11]], linestyle='dashed')\n",
    "axs[6,1].set_title(\"Left back knee angle\")\n",
    "axs[6,1].legend(['theta_11', 'theta_11 (smoothed)'])\n",
    "\n",
    "axs[7,0].plot(states_est_hist[:, [theta_12]])\n",
    "axs[7,0].plot(smooth_states_est_hist[:, [theta_12]], linestyle='dashed')\n",
    "axs[7,0].set_title(\"Right hip angle\")\n",
    "axs[7,0].legend(['theta_12', 'theta_12 (smoothed)'])\n",
    "\n",
    "axs[7,1].plot(states_est_hist[:, [theta_13]])\n",
    "axs[7,1].plot(smooth_states_est_hist[:, [theta_13]], linestyle='dashed')\n",
    "axs[7,1].set_title(\"Right back knee angle\")\n",
    "axs[7,1].legend(['theta_13', 'theta_13 (smoothed)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df columns -> frame, marker, x, y, z \n",
    "skeleton = []\n",
    "skeleton_smooth = []\n",
    "for frame in range(len(states_est_hist)):\n",
    "    marker_coords = get_3d_marker_coords(states_est_hist[frame])\n",
    "    marker_coords_smooth = get_3d_marker_coords(smooth_states_est_hist[frame])\n",
    "    for i, marker in enumerate(markers):\n",
    "        skeleton.append([frame, marker, *marker_coords[i]])\n",
    "        skeleton_smooth.append([frame, marker, *marker_coords_smooth[i]])\n",
    "        \n",
    "marker_df = pd.DataFrame(skeleton, columns=['frame', 'marker', 'x','y','z'])\n",
    "marker_smooth_df = pd.DataFrame(skeleton_smooth, columns=['frame', 'marker', 'x','y','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QApplication\n",
    "from pyqtgraph.Qt import QtCore, QtGui\n",
    "import pyqtgraph.opengl as gl\n",
    "import sys\n",
    "\n",
    "class PoseAnimation(object):\n",
    "    def __init__(self, positions, centered=False):\n",
    "        self.app = QApplication.instance()\n",
    "        if self.app == None:\n",
    "            self.app = QApplication([])\n",
    "        self.w = gl.GLViewWidget()\n",
    "        self.w.setGeometry(0, 110, 1920, 1080)\n",
    "        # self.w.setBackgroundColor('w')\n",
    "        self.w.show()\n",
    "        self.w.setWindowTitle(\"My Animation\")\n",
    "        self.w.setCameraPosition(distance=30, elevation=8)\n",
    "        self.frame = 0\n",
    "        self.n_frames = len(positions)\n",
    "        self.pos = positions\n",
    "        self.centered = centered\n",
    "\n",
    "        #Create links\n",
    "        self.links_indices = [\n",
    "            [0,1],[0,2],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[8,11],[14,17], #torso\n",
    "            [3,8],[4,8],[8,9],[9,10],                  #left front leg\n",
    "            [3,11],[4,11],[11,12],[12,13],             #right front leg\n",
    "            [4,14],[5,14],[14,15],[15,16],\n",
    "            [4,17],[5,17],[17,18],[18,19]\n",
    "        ]\n",
    "        \n",
    "        links = np.array([\n",
    "            [[self.pos[self.frame][a], self.pos[self.frame][b]] for [a,b] in self.links_indices]\n",
    "        ], dtype=np.float)\n",
    "        self.lines = gl.GLLinePlotItem(pos=links, color=[1.,0.,0.,1.], width=5, mode='lines')\n",
    "        self.w.addItem(self.lines)\n",
    "        \n",
    "        #Create scatter points\n",
    "        grid = gl.GLGridItem(glOptions='translucent')\n",
    "        grid.scale(1,1,1)\n",
    "        self.w.addItem(grid)\n",
    "        self.dots = gl.GLScatterPlotItem(color=[0.,0.,1.,1.], pos=self.pos[self.frame], size=0.05, pxMode=False) #, glOptions='translucent')\n",
    "        self.w.addItem(self.dots)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def start(self):\n",
    "        self.app.exec_()\n",
    "    \n",
    "    \n",
    "    def update(self):\n",
    "        \n",
    "        if self.frame < self.n_frames-1:\n",
    "            self.frame+=1\n",
    "        else:\n",
    "            self.frame = 0\n",
    "        links = np.array([\n",
    "            [[self.pos[self.frame][a], self.pos[self.frame][b]] for [a,b] in self.links_indices]\n",
    "        ], dtype=np.float)\n",
    "        dots = np.array(self.pos[self.frame])\n",
    "        if self.centered:\n",
    "            links[:,:] -= (self.pos[self.frame][0] - np.array([0,0,1]))\n",
    "            dots -= (self.pos[self.frame][0] - np.array([0,0,1]))\n",
    "        self.lines.setData(pos=links)\n",
    "        self.dots.setData(pos=dots)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def animate(self):\n",
    "        timer = QtCore.QTimer()\n",
    "        timer.timeout.connect(self.update)\n",
    "        timer.start(8)\n",
    "        self.start()\n",
    "        self.update()\n",
    "        \n",
    "        \n",
    "        \n",
    "positions = [get_3d_marker_coords(states) for states in states_est_hist]\n",
    "a = PoseAnimation(positions)\n",
    "a.animate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CHEETAH DLC ESTIMATES AND KF ESTIMATES\n",
    "\n",
    "videos_folder = os.path.join(ROOT_DATA_DIR,'../CheetahData/extrinsic/09_03_2019/Jules/Flick1')\n",
    "video_files = sorted([os.path.join(videos_folder, f) for f in os.listdir(videos_folder) if f.endswith('.mp4') and ('DLC' not in f)])\n",
    "\n",
    "print(video_files)\n",
    "\n",
    "vid_caps = [cv2.VideoCapture(v) for v in video_files]\n",
    "assert len(vid_caps) == n_cameras\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out_vid = cv2.VideoWriter('output.avi',fourcc, 10.0, (2704, 2280))\n",
    "\n",
    "for vc in vid_caps:\n",
    "    assert vc.isOpened()\n",
    "\n",
    "for frame in range(n_frames):\n",
    "    print(f\"Writing frame {frame}\\r\", end='')\n",
    "    img_tiled = np.zeros((1520*3, 2704*2, 3), dtype='uint8')\n",
    "    for i in range(n_cameras):\n",
    "        n_pts = 2*n_markers\n",
    "\n",
    "        # Plot image\n",
    "        vid_caps[i].set(cv2.CAP_PROP_POS_FRAMES, frame+start_frame)\n",
    "        ret, img = vid_caps[i].read()\n",
    "        \n",
    "        if ret:\n",
    "            # Plot pixels estimated\n",
    "            for [x, y] in h_function(states_est_hist[frame], *camera_params[i]):\n",
    "                if not (np.isnan(x) or np.isnan(y)) and (x >= 0) and (x <= 2704) and (y >= 0) and (y <= 1520):\n",
    "                    cv2.circle(img,(int(x),int(y)),6,(255,0,255),-1)\n",
    "                \n",
    "            # Plot pixels measured\n",
    "            pixels_2_plot = pixels_arr.copy()\n",
    "            pixels_2_plot[likelihood_arr.repeat(2, axis=1)<0.5] = np.nan\n",
    "            pixels_2_plot = pixels_2_plot[start_frame:end_frame]\n",
    "            pix_meas_x = pixels_2_plot[frame, i*n_pts:(i+1)*n_pts:2]\n",
    "            pix_meas_y = pixels_2_plot[frame, i*n_pts+1:(i+1)*n_pts:2]    \n",
    "            for x, y in zip(pix_meas_x, pix_meas_y):\n",
    "                if not (np.isnan(x) or np.isnan(y)):\n",
    "                    cv2.circle(img,(int(x),int(y)),6,(255,255,0),-1)\n",
    "            \n",
    "            h_start = 1520 * (i%3)\n",
    "            h_end = h_start + 1520\n",
    "            w_start = 2704 * (i//3)\n",
    "            w_end = w_start + 2704\n",
    "            img_tiled[h_start:h_end, w_start:w_end] = img\n",
    "    \n",
    "    out_vid.write(cv2.resize(img_tiled, (2704, 2280)))\n",
    "print(\"\\nDone!\")\n",
    "    \n",
    "for v in vid_caps:\n",
    "    v.release()\n",
    "    out_vid.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
